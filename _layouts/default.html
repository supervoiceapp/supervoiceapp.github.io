
<html>
	<head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1XTFM65VS2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1XTFM65VS2');
</script>
	<meta charset=“UTF-8”>

		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,600" rel="stylesheet">
		<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Open+Sans:400,bold,900,600">
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
		  <!-- Custom styles for this template -->
 		 <link href="css/custom.css" rel="stylesheet">

	  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
 	 <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>

		<title>SuperVoice</title>
	</head>
	<body>
		<div class = "global_container">
			<div class = "section"  >

				<h0>SUPERVOICE: Text-Independent Speaker Verification Using Ultrasound Energy in Human Speech</h0>
				<div class ="boxed">
					<p> SUPERVOICE is a text-Independent speaker verification system which ultilizes ultrasound in human speech. It can be integrated with any Deep Neural Network based speaker identification model. SUPERVOICE is highly accurate in the speaker recognition task, outperforming all existing speaker verification models. SUPERVOICE is also capable of differentiating between the speech from genuine human and replay audios from attackers. With SUPERVOICE, we are exploring a new direction of human voice research by scrutinizing the unique characteristics of human speech at the ultrasound frequency band. When considering human speech production, our research indicates that the high-frequency ultrasound components (e.g. speech fricatives) from 20 to 48 kHz can significantly enhance the security and accuracy of speaker verification. SUPERVOICE could significantly enhance the existing speaker verification systems.
					  This website shows the dataset we used to evaluate SUPERVOICE.
					</p>
					<!-- <p style="font-size:20px"><a href="papers/NDSS-surfingattack.pdf">Read the Paper</a>, -->

					<!-- <a href="#bibtex" data-toggle="collapse" role="button">
					Cite <i class="fa fa-quote-right" aria-hidden="true"></i></a>
						<div id="bibtex" style="margin-top: 1.5em;" class="collapse" align="left">
							<pre style="white-space: pre">
@inproceedings{yan2020surfingattack,
    author = {Yan, Qiben and Liu, Kehai and Zhou, Qin and Guo, Hanqing and Zhang, Ning},
    title = {SurfingAttack: Interactive Hidden Attack on Voice Assistants Using Ultrasonic Guided Wave},
    booktitle={Network and Distributed Systems Security (NDSS) Symposium},
    year = {2020},
}
</pre></p></div>
				</div> -->


				<h1> Team </h1>
					<div class ="boxed" style="margin-top=3em;">
						<p>
							SuperVoice was discovered by the following team of academic researchers:
						</p>
						<ul>
							<li><a href="https://hanqingguo.github.io"><strong>Hanqing Guo</strong></a> at <a href="http://seit.egr.msu.edu/">SEIT Lab</a>, <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
							<li><a href="http://cse.msu.edu/~qyan/"><strong>Qiben Yan</a></strong> at <a href="http://seit.egr.msu.edu/">SEIT Lab</a>, <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
							<li><a href="https://nick-ivanov.com/"><strong>Nick Ivanov</strong></a> at <a href="http://seit.egr.msu.edu/">SEIT Lab</a>, <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
							<li><strong>Ying Zhu</strong> at <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
							<li><a href="http://www.cse.msu.edu/~lxiao/"><strong>Li Xiao</strong></a> at <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
							<li><a href="https://comartsci.msu.edu/our-people/eric-j-hunter"><strong>Eric J. Hunter</strong></a> at <a href="https://comartsci.msu.edu/departments/communicative-sciences-and-disorders">Communicative Sciences & Disorders</a>, <a href="https://www.cse.msu.edu/">Michigan State University</a></li>
						</ul>
<!-- <p class="text-center"><strong>Contact us at <a href="mailto:surfingattack@gmail.com">surfingattack@gmail.com</a></strong></p> -->
<div class="Fb">
	<div class="Gb"><h3>7700</h3><h4>Audio Samples</h4></div>
		<div class="Gb"><h3>641 </h3><h4>minutes of audio</h4></div>
		<div class="Gb"><h3>305</h3><h4>of sentences</h4></div>
</div>

 <div class="text-center mt-auto" style="width:100%;margin-top: 1.5em; margin-bottom: 1.5em; display:flex;justify-content:space-around;align-items:center; flex-wrap: wrap;">
      <div>
        <img width = "280px" src="data/gender.png" alt="gender" class="img-fluid" />
				<div style = "height:10px"></div>
      </div>
        <img width="280px" src="data/age.png" alt="age" class="img-fluid" />
        <img width="280px" src="data/english.png" alt="english" class="img-fluid" />
 </div>
</div>


				<!--<h1>Voice-1</h1>-->

					<ul>
						<li class="question">
							<h2> Download</h2>
							<p style="font-size:20px"><b><a href="https://michiganstate-my.sharepoint.com/:f:/r/personal/qyan_msu_edu/Documents/Data/HFVoiceData/HFVoiceDate2?csf=1&web=1&e=z5chdU">CHECK HERE</a></b><br>
						<li class="question">
							<h2> Why we collect this dataset?</h2>
							<p class="answer">
							SUPERVOICE dataset (Voice-1 and Voice-2) is the first voice dataset with voice data collected by recorders with a high-frequency sampling rate as highly as 48kHz and 192kHz.
							</p>

							<h2> What is inside the dataset?</h2>
							<p class="answer">
							Voice-1 is collected by Avisoft condenser microphone CM16, which includes the voice data from 78 volunteers, totalling 7,800 utterances using 192 kHz sampling rate. Among the 78 volunteers, most of them are college students with ages ranging from 18 to 56, including 38 males and 40 females. Voice-2 is constructed by recording 25 sentences by 50 participants with different models of smartphones, which includes 1,250 utterances with 48 kHz sampling rate. <br><br>
							The table below shows a comparison with other high-profile datasets.
							</p>

							<img width = "1400px" src="pic/compare.png" alt="comparison" class="img-fluid" /><br>
							<h2> Dataset Size</h2>
							<p class="answer">
									77 person, 7700 audio samples, 100 audios/person
							</p>
					<h2>Dataset Design</h2>
					<p class="answer">
					There are 4 types of sentences included by the dataset.
					</p>
					<li class="answer">  &#9733<strong>Common:</strong>The common type contains 5 sentences, two of which are from the dialect set of TIMIT dataset, while the other three sentences are “This is a test", “Please identify me", and “OK, please recognize my voice". For this type of sentence, each participant will speak every sentence twice, resulting in 10 recordings.
</li>
					<li class="answer">  &#9733<strong>Compact:</strong>The compact type has 200 sentences in total. They are randomly chosen from the TIMIT dataset, and designed to provide a good coverage of phonemes, with extra occurrences of phonetic contexts that are considered either difficult or of particular interest. Each participant reads 40 sentences from this type.
</li>
					<li class="answer">  &#9733<strong>Fricative:</strong>The fricative commands are collected from the website ok-google.io, which provides commonly used commands on Google Assistant. We select 50 sentences that have fricative phonemes, e.g., “find my phone", “turn on my lights". Each speaker randomly picks 25 sentences from this type of commands.
 </li>
					<li class="answer"> &#9733<strong>Non-fricative:</strong>Similar to the fricative commands, the non-fricative commands are also collected from ok-google.io, which do not contain any fricative phonemes. We randomly pick 25 sentences and ask every participant read 25 sentences from this type</li>

				<h2>Sentences</h2>
					<p style="font-size:20px"><a href="sentences/full_sentences.pdf">CHECK HERE</a><br>
				<h2>Arrangement</h2>
				<p class="answer">
				We assign different speakers with different sentences, to assure every sentences are read by different speaker.
				</p>
				<img width = "200px" src="pic/arrange1.png" alt="arrange" class="img-fluid" />
				<img width = "200px" src="pic/arrange2.png" alt="arrange" class="img-fluid" />
				<img width = "200px" src="pic/arrange3.png" alt="arrange" class="img-fluid" />
				<img width = "200px" src="pic/arrange4.png" alt="arrange" class="img-fluid" />
        <h2>Samples</h2>
				<p class="answer">
				<b>Transcript:</b> She had your dark suit in greasy wash water all year.
			</p> <br>
				<audio controls>
						<source src="./samples/1.wav" type="audio/wav">
						Your browser does not support the <code>audio</code> element.
					</audio></td>

					<p class="answer">
						<b>Transcript:</b> Please identify me.
				</p> <br>
					<audio controls>
							<source src="./samples/4.wav" type="audio/wav">
							Your browser does not support the <code>audio</code> element.
						</audio></td>

						<p class="answer">
							<b>Transcript:</b> Don't ask me to carry an oily rage like that.
					</p> <br>
						<audio controls>
								<source src="./samples/7.wav" type="audio/wav">
								Your browser does not support the <code>audio</code> element.
							</audio></td>


	</body>
</html>
